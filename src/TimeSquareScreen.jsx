/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
*/

import * as THREE from "three";
import { useGLTF, PerspectiveCamera, useTexture } from "@react-three/drei";
import ProjectedMaterial from 'three-projected-material';
import { useFrame, useThree } from "@react-three/fiber";
import { useRef, useEffect, useMemo } from "react";

export default function TimeSquareScreen(props) {
    const { nodes, materials } = useGLTF("./timesquare-added-screen.glb");

    const meshRef = useRef();
    const cameraRef = useRef();
    const texture = useTexture('./test.png');
    let projectedMaterial;

    // scale to keep the image proportions and apply textureScale
    function computeScaledDimensions(texture, camera, cover) {
        // return some default values if the image hasn't loaded yet
        if (!texture.image) {
            return [1, 1];
        }

        // return if it's a video and if the video hasn't loaded yet
        if (texture.image.videoWidth === 0 && texture.image.videoHeight === 0) {
            return [1, 1];
        }

        const sourceWidth =
            texture.image.naturalWidth || texture.image.videoWidth || texture.image.clientWidth;
        const sourceHeight =
            texture.image.naturalHeight || texture.image.videoHeight || texture.image.clientHeight;

        const ratio = sourceWidth / sourceHeight;
        const ratioCamera = camera.aspect;
        const widthCamera = 1;
        const heightCamera = widthCamera * (1 / ratioCamera);
        let widthScaled;
        let heightScaled;
        if (cover ? ratio > ratioCamera : ratio < ratioCamera) {
            const width = heightCamera * ratio;
            widthScaled = 1 / ((width / widthCamera));
            heightScaled = 1;
        } else {
            const height = widthCamera * (1 / ratio);
            heightScaled = 1 / ((height / heightCamera));
            widthScaled = 1;
        }

        return [widthScaled, heightScaled];
    }

    // scale to keep the image proportions and apply textureScale
    let widthScaled, heightScaled;

    const vertexShader = /* glsl */ `
        uniform mat4 viewMatrixCamera;
        uniform mat4 projectionMatrixCamera;
    
        #ifdef USE_INSTANCING
        attribute vec4 savedModelMatrix0;
        attribute vec4 savedModelMatrix1;
        attribute vec4 savedModelMatrix2;
        attribute vec4 savedModelMatrix3;
        #else
        uniform mat4 savedModelMatrix;
        #endif
    
        varying vec3 vSavedNormal;
        varying vec4 vTexCoords;
        #ifndef ORTHOGRAPHIC
        varying vec4 vWorldPosition;
        #endif
    
        void main() {
            #ifdef USE_INSTANCING
            mat4 savedModelMatrix = mat4(
                savedModelMatrix0,
                savedModelMatrix1,
                savedModelMatrix2,
                savedModelMatrix3
            );
            #endif
        
            vSavedNormal = mat3(savedModelMatrix) * normal;
            vTexCoords = projectionMatrixCamera * viewMatrixCamera * savedModelMatrix * vec4(position, 1.0);
            #ifndef ORTHOGRAPHIC
            vWorldPosition = savedModelMatrix * vec4(position, 1.0);
            #endif
        
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
    `;

    const fragmentShader = /* glsl */ `
        uniform sampler2D projectedTexture;
        uniform bool isTextureLoaded;
        uniform bool isTextureProjected;
        uniform vec3 projPosition;
        uniform vec3 projDirection;
        uniform float widthScaled;
        uniform float heightScaled;
    
        varying vec3 vSavedNormal;
        varying vec4 vTexCoords;
        #ifndef ORTHOGRAPHIC
        varying vec4 vWorldPosition;
        #endif
    
        float mapRange(float value, float min1, float max1, float min2, float max2) {
            return min2 + (value - min1) * (max2 - min2) / (max1 - min1);
        }
    
        void main() {
            // clamp the w to make sure we don't project behind
            float w = max(vTexCoords.w, 0.0);
        
            vec2 uv = (vTexCoords.xy / w) * 0.5 + 0.5;
        
            // apply the corrected width and height
            uv.x = mapRange(uv.x, 0.0, 1.0, 0.5 - widthScaled / 2.0, 0.5 + widthScaled / 2.0);
            uv.y = mapRange(uv.y, 0.0, 1.0, 0.5 - heightScaled / 2.0, 0.5 + heightScaled / 2.0);
        
            // this makes sure we don't sample out of the texture
            bool isInTexture = (max(uv.x, uv.y) <= 1.0 && min(uv.x, uv.y) >= 0.0);
        
            // this makes sure we don't render also the back of the object
            #ifdef ORTHOGRAPHIC
            vec3 projectorDirection = projDirection;
            #else
            vec3 projectorDirection = normalize(projPosition - vWorldPosition.xyz);
            #endif
            float dotProduct = dot(vSavedNormal, projectorDirection);
            bool isFacingProjector = dotProduct > 0.0000001;
        
        
            vec4 diffuseColor = vec4(1.0, 1.0, 1.0, 1.0);
        
            if (isFacingProjector && isInTexture && isTextureLoaded && isTextureProjected) {
                vec4 textureColor = texture2D(projectedTexture, uv);
        
                // apply the material opacity
                textureColor.a *= 1.0;
        
                // https://learnopengl.com/Advanced-OpenGL/Blending
                diffuseColor = textureColor * textureColor.a + diffuseColor * (1.0 - textureColor.a);
            }
        
            gl_FragColor = diffuseColor;
        }
    `;

    let shaderMaterial = new THREE.ShaderMaterial({
        vertexShader: vertexShader,
        fragmentShader: fragmentShader
    });

    useEffect(() => {
        projectedMaterial = new ProjectedMaterial({
            camera: cameraRef.current, // the camera that acts as a projector
            texture: texture, // the texture being projected
        });
        meshRef.current.material = projectedMaterial;
        projectedMaterial.project(meshRef.current);

        [widthScaled, heightScaled] = computeScaledDimensions(
            texture,
            cameraRef.current,
            false
        );

        shaderMaterial.uniforms = projectedMaterial.uniforms;


        // console.log(meshRef.current);
        console.log(shaderMaterial);
    });

    const planeRef = useRef();
    const { camera } = useThree();

    useFrame(() => {
        planeRef.current.lookAt(camera.position);
    });

    return (
        <group {...props} dispose={null}>
            <PerspectiveCamera
                ref={cameraRef}
                name="Camera"
                makeDefault={false}
                far={50}
                near={0.1}
                fov={26.37}
                position={[-7.22, -1.48, 6.04]}
                rotation={[0.43, -0.93, 0.36]}
            />
            <mesh
                ref={meshRef}
                name="screen_outer_edge"
                castShadow
                receiveShadow
                geometry={nodes.screen_outer_edge.geometry}
                material={new THREE.MeshBasicMaterial({ color: 0x000000 })}
            />

            <mesh ref={planeRef} position={[0, -3, 0]} material={shaderMaterial}>
                <planeGeometry args={[5.900, 3.480, 1, 1]} />
            </mesh>
        </group>
    );
}

useGLTF.preload("./timesquare-added-screen.glb");
